python test_pipeline.py --model-to-evaluate="llama-3.3" --dataset=longfact --max-concurrent-tasks=10 --num-topics=50 --compute-baselines=True
